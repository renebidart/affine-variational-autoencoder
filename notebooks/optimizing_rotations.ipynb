{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing Affine Transforms\n",
    "\n",
    "### For testing:\n",
    "* Need to first check that all the right tensors require grad (maybe just print it out)\n",
    "* Need to check that the correct tensors are changing in the optimization (use a check to see what is changing and print them out) *** Maybe looking at the optimizer is enough to know what ones can be updated, but won't show what will in practice.\n",
    "\n",
    "* Next level debugging is that the syntax is all good, but checking that there aren't some exploding gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "# Nicer way to import the module?\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from utils.display import read_img_to_np, torch_to_np\n",
    "from utils.norms import MNIST_norm\n",
    "import model.model as module_arch\n",
    "import data_loader.data_loaders as module_data\n",
    "import model.loss as module_loss\n",
    "import model.metric as module_metric\n",
    "from model.model import AffineVAE\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "from data_loader.data_loaders import make_generators_MNIST, make_generators_MNIST_CTRNFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_loaders_config(PATH, old_gpu='cuda:0', new_gpu='cuda:1'):\n",
    "    \"\"\"PATH: path to dir where training results of a run are saved\"\"\"\n",
    "    PATH = Path(PATH)\n",
    "    config_loc = PATH / 'config.json'\n",
    "    weight_path = PATH / 'model_best.pth'\n",
    "    config = json.load(open(config_loc))\n",
    "    \n",
    "    \n",
    "    def get_instance(module, name, config, *args):\n",
    "        return getattr(module, config[name]['type'])(*args, **config[name]['args'])\n",
    "\n",
    "    data_loader = get_instance(module_data, 'data_loader', config)['train']\n",
    "    valid_data_loader = get_instance(module_data, 'data_loader', config)['val']\n",
    "    model = get_instance(module_arch, 'arch', config)\n",
    "    model = model.to(torch.device(new_gpu))\n",
    "    checkpoint = torch.load(weight_path, map_location={'cuda:0': 'cuda:1'})\n",
    "    state_dict = checkpoint['state_dict']\n",
    "    \n",
    "    if config['n_gpu'] > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    model.load_state_dict(state_dict)\n",
    "    model = model.to(device).eval()\n",
    "    \n",
    "    loss_fn = get_instance(module_loss, 'loss', config)\n",
    "    metric_fns = [getattr(module_metric, met) for met in config['metrics']]\n",
    "    \n",
    "    return model, data_loader, valid_data_loader, loss_fn, metric_fns, config\n",
    "\n",
    "\n",
    "# def display_batch(x, recon_x):\n",
    "#     \"\"\"Display tensor images\"\"\"\n",
    "#     fig, ax = plt.subplots(x.size()[0], 2, sharex='col', sharey='row',figsize=(10,10))\n",
    "#     for i in range(x.size()[0]):\n",
    "#         ax[i, 0].imshow(torch_to_np(x[i]), cmap='Greys',  interpolation='nearest')\n",
    "#         ax[i, 1].imshow(torch_to_np(recon_x[i]), cmap='Greys',  interpolation='nearest')\n",
    "#         ax[i, 0].axis('off')\n",
    "#         ax[i, 1].axis('off')\n",
    "#     plt.show()\n",
    "\n",
    "        \n",
    "# def visualize_dataloader(data_loader, device, num_samples=6, bw=True):\n",
    "#     \"\"\"Randomly sample from dataloader and display\"\"\"\n",
    "#     with torch.cuda.device(device.index):\n",
    "#         fig, ax = plt.subplots(int(num_samples/2), 2, sharex='col', sharey='row',figsize=(10,10))\n",
    "#         for i in range(0, int(num_samples/2)):\n",
    "#             # sample randomly from the nth batch for the nth row of imgs\n",
    "#             data, label = next(iter(data_loader))\n",
    "#             tensor_img = data[random.randint(0, data.size()[0]),:, :, :]\n",
    "#             ax[i, 0].imshow(torch_to_np(tensor_img), cmap='Greys',  interpolation='nearest')\n",
    "#             tensor_img = data[random.randint(0, data.size()[0]), :, :, :]\n",
    "#             ax[i, 1].imshow(torch_to_np(tensor_img), cmap='Greys',  interpolation='nearest')\n",
    "#             print(f'tensor_img size: {tensor_img.size()}')\n",
    "#             print(f'Max: {torch.max(tensor_img)}, Min: {torch.min(tensor_img)}')\n",
    "#             ax[i, 0].axis('off')\n",
    "#             ax[i, 1].axis('off')\n",
    "    \n",
    "\n",
    "# def display_results_auto(vae_model, config, device, rotate=0, pad = 6,\n",
    "#                          norm=None, num_samples=3, data='bw', size = 28, label_col_name='label', save_loc=None):\n",
    "#     \"\"\" QUESTIONABLE, REDO IT\"\"\"\n",
    "#     with torch.cuda.device(device.index): # ??? Why the fuck???        \n",
    "#         files_dict_loc = config['data_loader']['args']['files_dict_loc']\n",
    "#         with open(files_dict_loc, 'rb') as f:\n",
    "#             files_df = pickle.load(f)['train']\n",
    "            \n",
    "#         if label_col_name:\n",
    "#             all_labels = files_df[label_col_name].unique()\n",
    "#         else:\n",
    "#             all_labels = list(range(num_samples))\n",
    "#         row_names = []\n",
    "#         col_names = ['Original', \"Reconstructed\"]\n",
    "\n",
    "#         fig, ax = plt.subplots(num_samples, 2, sharex='col', sharey='row',figsize=(10,10))\n",
    "\n",
    "#         for i, label in enumerate(all_labels[0:num_samples]):\n",
    "#             if label_col_name:\n",
    "#                 sample_df = files_df.loc[files_df[label_col_name] == label].sample(n=1)\n",
    "#                 label = sample_df[label_col_name].iloc[0]\n",
    "#                 row_names.append(label)\n",
    "#             else:\n",
    "#                 sample_df = files_df.sample(n=1)\n",
    "#             img_path = sample_df['path'].iloc[0]\n",
    "\n",
    "#             if data == 'bw': # Assume MNIST\n",
    "#                 img = read_img_to_np(img_path, bw=True)\n",
    "#                 transform = transforms.Compose([\n",
    "#                                                 transforms.RandomRotation((rotate, rotate), expand=True),\n",
    "#                                                 transforms.Resize(size),\n",
    "#                                                 transforms.Pad((pad, pad)),\n",
    "#                                                 transforms.ToTensor(),\n",
    "#                                                 transforms.Normalize(*MNIST_norm)])\n",
    "#             else:\n",
    "#                 img = read_img_to_np(img_path, bw=False, size=size)\n",
    "#                 transform = transforms.Compose([\n",
    "#                                                 transforms.RandomRotation((rotate, rotate), expand=True),\n",
    "#                                                 transforms.Resize(size),\n",
    "#                                                 transforms.ToTensor(),\n",
    "#                                                 transforms.Normalize(*norm)])\n",
    "\n",
    "#             tensor_img = transform(Image.open(img_path)).unsqueeze(0).to(device)\n",
    "#             tensor_label = torch.from_numpy(np.array(label)).unsqueeze(0).type(torch.LongTensor).to(device)\n",
    "#             output = vae_model(tensor_img,  deterministic=False)\n",
    "#             recon_x = output[0]\n",
    "            \n",
    "#             ax[i, 0].imshow(torch_to_np(tensor_img), cmap='Greys',  interpolation='nearest')\n",
    "#             ax[i, 1].imshow(torch_to_np(recon_x), cmap='Greys',  interpolation='nearest')\n",
    "#             ax[i, 0].axis('off')\n",
    "#             ax[i, 1].axis('off')\n",
    "\n",
    "#         for curr_ax, col in zip(ax[0], col_names):\n",
    "#             curr_ax.set_title(col)\n",
    "#         if label_col_name:\n",
    "#             for curr_ax, row in zip(ax[:,0], row_names):\n",
    "#                 curr_ax.set_ylabel(row, rotation=0, size='large')\n",
    "#         if save_loc:\n",
    "#             plt.savefig(save_loc, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_size(img, new_size):\n",
    "    delta_width = new_size - img.size()[1]\n",
    "    delta_height = new_size - img.size()[2]\n",
    "    pad_width = delta_width //2\n",
    "    pad_height = delta_height //2\n",
    "    img = F.pad(img, (pad_height, pad_height, pad_width, pad_width), 'constant', 0)\n",
    "    return img\n",
    "\n",
    "def rotate_mnist_batch(x, return_size=40, fixed_rotation=None):\n",
    "    \"\"\"Rotate batch without squishing the img. Pad all imgs to same size\"\"\"\n",
    "    batch_size = x.shape[0]\n",
    "    rot_x = torch.zeros((batch_size, 1, return_size, return_size))\n",
    "    for i in range(batch_size):\n",
    "        img = TF.to_pil_image(x[i, :, :])\n",
    "        if fixed_rotation:\n",
    "            img = TF.rotate(img, fixed_rotation)\n",
    "\n",
    "        img = transforms.ToTensor()(img)\n",
    "        if return_size:\n",
    "            img = pad_to_size(img, return_size)\n",
    "        # MNIST norm, wrong because imgs are padded\n",
    "        img = transforms.Normalize((0.1307,), (0.3081,))(img)\n",
    "        rot_x[i, :, :, :] = img\n",
    "    return rot_x\n",
    "    \n",
    "\n",
    "def get_vae_MNIST_perf(model, data_loader, loss_fn, metric_fns, device, fixed_rotation, return_size):\n",
    "    \"\"\"Evaluate performance on MNIST Dataset using a given rotation\n",
    "    \n",
    "    Dataloader should be MNISTCustomTRNFS with size=28x28, unnormalized, not rotated\"\"\"\n",
    "\n",
    "    with torch.cuda.device(device.index):\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "        total_loss = 0.0\n",
    "        total_metrics = torch.zeros(len(metric_fns))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (data, target) in enumerate(tqdm(data_loader)):\n",
    "                batch_size = data.shape[0]\n",
    "                new_data = rotate_mnist_batch(data, return_size=40, fixed_rotation=fixed_rotation)\n",
    "                new_data, target = new_data.to(device), target.to(device)\n",
    "                output = model(new_data, deterministic=True)\n",
    "\n",
    "                # computing loss, metrics on test set\n",
    "                loss = loss_fn(output, new_data)\n",
    "                total_loss += loss.item() * batch_size\n",
    "                for i, metric in enumerate(metric_fns):\n",
    "                    total_metrics[i] += metric(output, new_data) * batch_size\n",
    "\n",
    "        n_samples = len(data_loader.sampler)\n",
    "        log = {'loss': total_loss / n_samples}\n",
    "        log.update({met.__name__ : total_metrics[i].item() / n_samples for i, met in enumerate(metric_fns)})\n",
    "        return log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing rotation using SGD and random restarts\n",
    "* Can compute gradient of $\\theta$ to optimize the rotation to minimize VAE loss\n",
    "* Random restarts are needed because this tends to get caught in local optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AFFINE_MNIST_rot_perf(model, data_loader, loss_fn, device, fixed_rotation, \n",
    "                          optimize=False, iterations=0, num_rand_restarts=200, num_imgs=1000):\n",
    "    \"\"\"Evaluate performance on MNIST Dataset using a given rotation\n",
    "    Dataloader should be MNISTCustomTRNFS with size=28x28, unnormalized, not rotated\"\"\"\n",
    "\n",
    "    with torch.cuda.device(device.index):\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (data, target) in enumerate(data_loader):\n",
    "                batch_size = data.shape[0]\n",
    "                rot_x = rotate_mnist_batch(data, return_size=40, fixed_rotation=fixed_rotation)\n",
    "                rot_x, target = rot_x.to(device), target.to(device)\n",
    "                if optimize:\n",
    "                    best_affine, loss = affine_model.optimize_rotation(rot_x, num_times=num_rand_restarts, \n",
    "                                                                       iterations=iterations)\n",
    "                else:\n",
    "                    output = model(rot_x, deterministic=True, theta=0.0)\n",
    "                    loss = loss_fn(output, rot_x).item()\n",
    "\n",
    "                total_loss += loss * batch_size\n",
    "                if i>num_imgs:\n",
    "                    break\n",
    "\n",
    "        n_samples = len(data_loader.sampler)\n",
    "        log = {'loss': total_loss / num_imgs}\n",
    "        return log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab decent AVAE and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_loc = '/media/rene/data/equivariance/mnist/vae_mnist_L16/0129_230250'\n",
    "VAE, data_loader, valid_data_loader, loss_fn, metric_fns, config = get_model_loaders_config(config_loc, old_gpu='cuda:1', new_gpu='cuda:0')\n",
    "VAE = VAE.to(device)\n",
    "\n",
    "AffineVAE = getattr(module_arch, 'AffineVAE')\n",
    "affine_model = AffineVAE(pre_trained_VAE=VAE, img_size=28, input_dim=1, output_dim=1, latent_size=8, use_STN=False)\n",
    "affine_model = affine_model.to(device)\n",
    "\n",
    "files_dict_loc = '/media/rene/data/MNIST/files_dict.pkl'\n",
    "data_loaders = make_generators_MNIST_CTRNFS(files_dict_loc, batch_size=1, num_workers=4, \n",
    "                                            return_size=28, rotation_range=None, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 2 Loss: 669.2090291748046\n",
      "Iterations: 5 Loss: 664.2208488464355\n",
      "Iterations: 10 Loss: 658.0452225341797\n",
      "Iterations: 20 Loss: 660.5350748901367\n",
      "Iterations: 40 Loss: 653.7899044799805\n"
     ]
    }
   ],
   "source": [
    "for iterations in [2, 5, 10, 20, 40]:\n",
    "    log = AFFINE_MNIST_rot_perf(affine_model, data_loaders['val'], loss_fn, device, fixed_rotation=45, \n",
    "                                optimize=True, iterations=iterations, num_rand_restarts=1, num_imgs=1000)\n",
    "    print(f\"Iterations: {iterations} Loss: {log['loss']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 2 Loss: 619.0337117309571\n",
      "Iterations: 5 Loss: 612.3658827819825\n",
      "Iterations: 10 Loss: 614.3349027099609\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-a7522d52544d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0miterations\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     log = AFFINE_MNIST_rot_perf(affine_model, data_loaders['val'], loss_fn, device, fixed_rotation=45, \n\u001b[0;32m----> 3\u001b[0;31m                                 optimize=True, iterations=iterations, num_rand_restarts=10, num_imgs=1000)\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Iterations: {iterations} Loss: {log['loss']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-dafbeeb4066e>\u001b[0m in \u001b[0;36mAFFINE_MNIST_rot_perf\u001b[0;34m(model, data_loader, loss_fn, device, fixed_rotation, optimize, iterations, num_rand_restarts, num_imgs)\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     best_affine, loss = affine_model.optimize_rotation(rot_x, num_times=num_rand_restarts, \n\u001b[0;32m---> 18\u001b[0;31m                                                                        iterations=iterations)\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrot_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/rene/code/equivariance/model/model.py\u001b[0m in \u001b[0;36moptimize_rotation\u001b[0;34m(self, x, num_times, iterations, KLD_weight)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                     \u001b[0mx_affine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maffine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maffine_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                     \u001b[0mmu_logvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_affine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreparameterize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu_logvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                     \u001b[0mrecon_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/rene/code/equivariance/model/model.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             affine_params = torch.cat([torch.cos(theta), torch.sin(theta), \n\u001b[0m\u001b[1;32m    206\u001b[0m                                            \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                                            \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/HVAE/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for iterations in [2, 5, 10, 20, 40]:\n",
    "    log = AFFINE_MNIST_rot_perf(affine_model, data_loaders['val'], loss_fn, device, fixed_rotation=45, \n",
    "                                optimize=True, iterations=iterations, num_rand_restarts=10, num_imgs=1000)\n",
    "    print(f\"Iterations: {iterations} Loss: {log['loss']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand Restarts: 5 Loss: 6.292737271118164\n",
      "Rand Restarts: 10 Loss: 6.367885220336914\n",
      "Rand Restarts: 20 Loss: 6.184860906982422\n",
      "Rand Restarts: 40 Loss: 6.0255543212890625\n"
     ]
    }
   ],
   "source": [
    "for rand_restarts in [5, 10, 20, 40]:\n",
    "    log = AFFINE_MNIST_rot_perf(affine_model, data_loaders['val'], loss_fn, device, fixed_rotation=45, \n",
    "                                optimize=True, iterations=20, num_rand_restarts=rand_restarts, num_imgs=1000)\n",
    "    print(f\"Rand Restarts: {rand_restarts} Loss: {log['loss']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of optimization over different rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rotation: 0\n"
     ]
    }
   ],
   "source": [
    "config_loc = '/media/rene/data/equivariance/mnist/vae_mnist_L16/0129_230250'\n",
    "VAE, data_loader, valid_data_loader, loss_fn, metric_fns, config = get_model_loaders_config(config_loc, old_gpu='cuda:1', new_gpu='cuda:0')\n",
    "VAE = VAE.to(device)\n",
    "\n",
    "AffineVAE = getattr(module_arch, 'AffineVAE')\n",
    "affine_model = AffineVAE(pre_trained_VAE=VAE, img_size=28, input_dim=1, output_dim=1, latent_size=8, use_STN=False)\n",
    "affine_model = affine_model.to(device)\n",
    "\n",
    "files_dict_loc = '/media/rene/data/MNIST/files_dict.pkl'\n",
    "data_loaders = make_generators_MNIST_CTRNFS(files_dict_loc, batch_size=1, num_workers=4, \n",
    "                                            return_size=28, rotation_range=None, normalize=False)\n",
    "\n",
    "results = pd.DataFrame()\n",
    "results_opt = pd.DataFrame()\n",
    "for rotation in range(0, 180, 15):\n",
    "    print(f'rotation: {rotation}')\n",
    "    log = AFFINE_MNIST_rot_perf(affine_model, data_loaders['val'], loss_fn, device, fixed_rotation=rotation, \n",
    "                                optimize=False, iterations=0, num_rand_restarts=0, num_imgs=1000)\n",
    "    log['rotation'] = rotation\n",
    "    results = results.append(log, ignore_index=True)\n",
    "    \n",
    "    log_opt = AFFINE_MNIST_rot_perf(affine_model, data_loaders['val'], loss_fn, device, fixed_rotation=rotation, \n",
    "                                optimize=True, iterations=10, num_rand_restarts=40, num_imgs=1000)\n",
    "    log_opt['rotation'] = rotation\n",
    "    results_opt = results_opt.append(log_opt, ignore_index=True)\n",
    "\n",
    "results.to_csv('/media/rene/code/equivariance/results/affine_rot_nonopt_sgd20_r40.csv')\n",
    "results_opt.to_csv('/media/rene/code/equivariance/results/affine_rot_opt_sgd20_r40.csv')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(results['rotation'], results['loss'], label=\"VAE\")\n",
    "ax.plot(results_opt['rotation'], results_opt['loss'], label=\"AVAE\")\n",
    "\n",
    "ax.set(xlabel='Rotation', ylabel='VAE Loss',\n",
    "       title='Effect of optimizing rotation on VAE loss')\n",
    "ax.legend(loc='best')\n",
    "\n",
    "plt.savefig('/media/rene/code/equivariance/imgs/rotation_opt_sgd20_r40.png', bbox='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "1. Check graphs/results\n",
    "2. Clean this notebook\n",
    "3. Extend to jointly optimizing across a few variables - Finish making the new trainer with the unreduced loss and add in the optimization loop.\n",
    "4. Test it and run it on the real datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing rotation during training\n",
    "* Goal is to make a network that will represent all images at some cannonical orientation while being trained on variable orientation images.\n",
    "* This should result in an overall more simple model able to do the same work.\n",
    "* Switch between optimizing the model parameters, and optimizing the network.\n",
    "* Could also do it on one batch at a fixed orientation first, but this is much less cool so we won't\n",
    "\n",
    "For each batch:\n",
    "1. Optimize the rotation parameters (randomly)\n",
    "2. Do the backward pass to update the weights, but also update theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vae_loss_unreduced(output, target, KLD_weight=1):\n",
    "    recon_x, mu_logvar  = output\n",
    "    mu = mu_logvar[:, 0:int(mu_logvar.size()[1]/2)]\n",
    "    logvar = mu_logvar[:, int(mu_logvar.size()[1]/2):]\n",
    "    KLD = -0.5 * torch.sum(1 + 2 * logvar - mu.pow(2) - (2 * logvar).exp(), dim=1)\n",
    "    BCE = F.mse_loss(recon_x, target, reduction='none')    \n",
    "    BCE = torch.sum(BCE, dim=(1, 2, 3))\n",
    "    loss = BCE + KLD_weight*KLD\n",
    "    return loss\n",
    "\n",
    "\n",
    "data, target = next(iter(data_loader))\n",
    "batch_size = data.shape[0]\n",
    "rot_x = rotate_mnist_batch(data, return_size=40, fixed_rotation=45)\n",
    "rot_x, target = rot_x.to(device), target.to(device)\n",
    "output = affine_model(rot_x, deterministic=True)\n",
    "loss = vae_loss_unreduced(output, rot_x)\n",
    "loss.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from base import BaseModel\n",
    "from model.loss import make_vae_loss\n",
    "\n",
    "\n",
    "class TESTAffineVAE(nn.Module):\n",
    "    def __init__(self, pre_trained_VAE=None, img_size=28, input_dim=1, output_dim=1, latent_size=16, rotation_only=False):\n",
    "        \"\"\"Do we always need the device whenever we're creating tensors in the model? Whats the proper way to do this?\"\"\"\n",
    "        super(TESTAffineVAE, self).__init__()\n",
    "        if pre_trained_VAE is None:\n",
    "            self.VAE = VAE(input_dim=input_dim, output_dim=output_dim, latent_size=latent_size, img_size=img_size)\n",
    "        else:\n",
    "            self.VAE = pre_trained_VAE\n",
    "        self.latent_size = 16\n",
    "        self.img_size = img_size\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.rotation_only = rotation_only\n",
    "        self.theta = None\n",
    "        self.affine_params=None\n",
    "        self.optim_params=None\n",
    "        \n",
    "#         mu_logvar = torch.nn.Parameter(torch.randn((1, 2*self.latent_size), device=\"cuda\", requires_grad=True))\n",
    "#         self.register_parameter('mu_logvar', mu_logvar) \n",
    "#         recon_x = torch.nn.Parameter(torch.randn((1), device=\"cuda\", requires_grad=True))\n",
    "#         self.register_parameter('recon_x', mu_logvar) \n",
    "\n",
    "            \n",
    "#     def theta_to_affine(self, theta, affine_params):\n",
    "#         affine_params[:, 0, 0] = torch.cos(theta)\n",
    "#         affine_params[:, 0, 1] = torch.sin(theta)\n",
    "#         affine_params[:, 1, 0] = -1*torch.sin(theta)\n",
    "#         affine_params[:, 1, 1] = torch.cos(theta)\n",
    "#         return affine_params\n",
    "\n",
    "    def affine(self, x, affine_params, padding_mode='zeros'):\n",
    "        grid = F.affine_grid(affine_params, x.size()).cuda()\n",
    "        x = F.grid_sample(x, grid, padding_mode=padding_mode)\n",
    "        return x\n",
    "    \n",
    "    def affine_inv(self, x, affine_params, padding_mode='zeros'):\n",
    "        inv_affine_params = torch.cuda.FloatTensor(affine_params.size()).fill_(0)\n",
    "        A_inv =  torch.inverse(affine_params[:, :, :2].squeeze())\n",
    "        b = affine_params[:, : , 2:]\n",
    "        b_inv = torch.matmul(A_inv, b)\n",
    "        b_inv = b_inv.squeeze()\n",
    "        inv_affine_params[:, :2, :2] = A_inv\n",
    "        inv_affine_params[:, :, 2] = -1*b_inv\n",
    "        grid = F.affine_grid(inv_affine_params, x.size()).cuda()\n",
    "        x = F.grid_sample(x, grid, padding_mode=padding_mode)\n",
    "        return x\n",
    "    \n",
    "    def vae_loss(self, output, target, KLD_weight=1):\n",
    "            \"\"\"loss is BCE + KLD. target is original x\"\"\"\n",
    "            recon_x, mu_logvar  = output\n",
    "            mu = mu_logvar[:, 0:int(mu_logvar.size()[1]/2)]\n",
    "            logvar = mu_logvar[:, int(mu_logvar.size()[1]/2):]\n",
    "            KLD = -0.5 * torch.sum(1 + 2 * logvar - mu.pow(2) - (2 * logvar).exp())\n",
    "            BCE = F.mse_loss(recon_x, target, reduction='sum')\n",
    "            loss = BCE + KLD_weight*KLD\n",
    "            return loss\n",
    "    \n",
    "    def opt_latent(self, x, iterations=50, num_times=1):\n",
    "        deterministic=True\n",
    "        lr = .01\n",
    "        \n",
    "        with torch.enable_grad():\n",
    "            for trial in range(num_times):\n",
    "                theta = torch.cuda.FloatTensor(1).uniform_(-2*math.pi, 2*math.pi)\n",
    "                theta = theta.data.clone().detach().requires_grad_(True).cuda()\n",
    "                optimizer = optim.Adam([theta], lr=lr)\n",
    "\n",
    "                for i in range(iterations):\n",
    "                    affine_params = torch.cat([torch.cos(theta), torch.sin(theta), \n",
    "                                       torch.tensor([0.0], requires_grad=True, device=\"cuda\"), \n",
    "                                       -1*torch.sin(theta), torch.cos(theta),\n",
    "                                       torch.tensor([0.0], requires_grad=True, device=\"cuda\")]).view(-1, 2, 3)\n",
    "                    \n",
    "                    x_affine = self.affine(x, affine_params)\n",
    "                    print('x_affine.requires_grad', x_affine.requires_grad)\n",
    "                    mu_logvar = self.VAE.encode(x_affine)\n",
    "                    z = self.VAE.reparameterize(mu_logvar, deterministic=deterministic)\n",
    "                    recon_x = self.VAE.decode(z)\n",
    "                    recon_x = self.affine_inv(recon_x, affine_params)\n",
    "                    loss = self.vae_loss((recon_x, mu_logvar), x)\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            return loss.item()\n",
    "        \n",
    "        \n",
    "#         with torch.enable_grad():\n",
    "#             for trial in range(num_times):\n",
    "#                 print(trial)\n",
    "#                 mu_logvar = torch.randn((1, 2*self.latent_size), device=\"cuda\", requires_grad=True)\n",
    "#                 mu_logvar = mu_logvar.data.clone().detach().requires_grad_(True).cuda()\n",
    "#                 optimizer = optim.Adam([mu_logvar], lr=lr)\n",
    "\n",
    "#                 for i in range(iterations):\n",
    "#                     z = self.VAE.reparameterize(mu_logvar, deterministic=deterministic)\n",
    "#                     recon_x = self.VAE.decode(z)\n",
    "#                     recon_x = self.affine_inv(recon_x, affine_params)\n",
    "#                     loss = self.vae_loss((recon_x, mu_logvar), img)\n",
    "#                     optimizer.zero_grad()\n",
    "#                     loss.backward()\n",
    "#                     optimizer.step()\n",
    "#                     print(loss.item())\n",
    "#             return loss.item()\n",
    "            \n",
    "\n",
    "    def optimize_affine_params(self, x, only_rotation=False, only_shear=False, num_times=100, iterations=50, KLD_weight=1):\n",
    "        with torch.autograd.set_detect_anomaly(True):\n",
    "            vae_loss = make_vae_loss(KLD_weight=1)\n",
    "\n",
    "            lr = .01\n",
    "            best_loss = 10000000000000\n",
    "\n",
    "            for trial in range(num_times):\n",
    "                if only_rotation:\n",
    "                    x_rot = torch.tensor([0.0], dtype=torch.float32,\\\n",
    "                                         requires_grad=True, device = \"cuda\")\n",
    "                    x_sin = torch.sin(x_rot)\n",
    "                    print('x_sin.requires_grad', x_sin.requires_grad)\n",
    "                    \n",
    "#                     print(type(self.VAE.parameters()))\n",
    "#                     print(type(list(self.VAE.parameters())[0]))\n",
    "#                     theta = nn.Parameter(torch.from_numpy(np.random.uniform(-2*math.pi, 2*math.pi, 1)).float().clone().detach().cuda())\n",
    "                    theta = nn.Parameter(torch.cuda.FloatTensor(1).uniform_(-2*math.pi, 2*math.pi))\n",
    "#                     theta = torch.tensor(torch.cuda.FloatTensor([0.0]).uniform_(-2*math.pi, 2*math.pi).data, requires_grad=True)\n",
    "#                     print(theta)\n",
    "#                     print('theta.requires_grad', theta.requires_grad)\n",
    "#                     print('theta[0].requires_grad', theta[0].requires_grad)\n",
    "#                     add = torch.add(theta, 2.0)\n",
    "#                     abc = torch.sin(theta)\n",
    "#                     print('abc.requires_grad', abc.requires_grad)\n",
    "#                     print('add.requires_grad', add.requires_grad)\n",
    "\n",
    "                    affine_params = torch.cat([torch.cos(theta), torch.sin(theta), \n",
    "                               torch.tensor([0.0], requires_grad=False, device=\"cuda\"), \n",
    "                               -1*torch.sin(theta), torch.cos(theta),\n",
    "                               torch.tensor([0.0], requires_grad=False, device=\"cuda\")]).view(-1, 2, 3)\n",
    "                    \n",
    "                elif only_shear:\n",
    "#                     c_x = torch.cuda.FloatTensor([0.0]).uniform_(1, 1.5)\n",
    "                    c_x = torch.cuda.FloatTensor([0.0]).uniform_(-.3, .3)\n",
    "                    c_y = torch.cuda.FloatTensor([0.0]).uniform_(-.3, .3)\n",
    "#                     c_y = torch.cuda.FloatTensor([0.0]).uniform_(.6, 1.4)\n",
    "\n",
    "                    optim_params = [c_x, c_y]\n",
    "                    affine_params = torch.cat([torch.tensor([1.0], requires_grad=True, device=\"cuda\"), c_x, \n",
    "                               torch.tensor([0.0], requires_grad=True, device=\"cuda\"), \n",
    "                               c_y, torch.tensor([1.0], requires_grad=True, device=\"cuda\"), \n",
    "                               torch.tensor([0.0], requires_grad=True, device=\"cuda\")]).view(-1, 2, 3)\n",
    "                                        \n",
    "                else: # initialize to some resonable amount of scaling. This currently includes weird shears.\n",
    "                    affine_params = 4*torch.rand(x.size()[0], 2, 3, requires_grad=True) -2\n",
    "                    optim_params = [affine_params]\n",
    "                    \n",
    "                if iterations > 0:\n",
    "                    x = nn.Parameter(x)\n",
    "                    optimizer = torch.optim.Adam(optim_params, lr=lr)\n",
    "                    print('optimizer', optimizer)\n",
    "                    for i in range(iterations):\n",
    "                        print('x.requires_grad', x.requires_grad)\n",
    "                        print('affine_params.requires_grad', affine_params.requires_grad)\n",
    "                        x_affine = self.affine(x, affine_params)\n",
    "                        print('x_affine.requires_grad', x_affine.requires_grad)\n",
    "                        mu_logvar = self.VAE.encode(x_affine)\n",
    "                        z = self.VAE.reparameterize(mu_logvar, deterministic=True)\n",
    "                        recon_x = self.VAE.decode(z)\n",
    "                        recon_x = self.affine_inv(recon_x, affine_params)\n",
    "                        print('recon_x.requires_grad', recon_x.requires_grad)\n",
    "                        \n",
    "                        loss = vae_loss((recon_x, mu_logvar), x)\n",
    "#                         print(loss.item(), self.theta, self.affine_params[0, 0, 0])\n",
    "#                         print(self.VAE.dec_conv1.weight.grad.data.sum())\n",
    "                        \n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                        if loss.item() < best_loss:\n",
    "                            best_loss = loss.item()\n",
    "                            best_affine_params = affine_params\n",
    "                else:\n",
    "                    x_affine = self.affine(x, affine_params)\n",
    "                    recon_x, mu_logvar = self.VAE(x_affine, deterministic=True)\n",
    "                    recon_x = self.affine_inv(recon_x, affine_params)\n",
    "                    loss = vae_loss((recon_x, mu_logvar), x)\n",
    "                    if loss.item() < best_loss:\n",
    "                        best_loss = loss.item()\n",
    "                        best_affine_params = affine_params\n",
    "            return best_affine_params, best_loss\n",
    "\n",
    "        \n",
    "    def forward(self, x, theta=None, affine_params=None, deterministic=False, return_affine=False):\n",
    "        \"\"\"forward pass with optionally learned affine transform. \n",
    "        \n",
    "        !! If no affine passed in will also check if model has some\n",
    "\n",
    "        Options:\n",
    "        None: This is the identity transform, equivalent to normal VAE\n",
    "\n",
    "        Delete::::\n",
    "        explicit: will use the affine_params provided, else equivalent to None\n",
    "        stn: use learned params. If STN module isn't trained, will give nonsense\n",
    "        optimized: optimize affine params to minimize reconstruction loss\n",
    "        rot_optimized: optimized, but constrained to rotations.\n",
    "        \"\"\"\n",
    "\n",
    "        # learned affine \n",
    "        if self.use_STN: \n",
    "            affine_params = self.get_stn_params(x)\n",
    "            \n",
    "        # initalize affine to rotation \n",
    "        elif theta is not None:\n",
    "            theta = torch.cuda.FloatTensor([theta])\n",
    "            affine_params = torch.cat([torch.cos(theta), torch.sin(theta), \n",
    "                                           torch.tensor([0.0], requires_grad=True, device=\"cuda\"), \n",
    "                                           -1*torch.sin(theta), torch.cos(theta), \n",
    "                                           torch.tensor([0.0], requires_grad=True, device=\"cuda\")]).view(-1, 2, 3)\n",
    "\n",
    "        # initialize to identity for each image if affine param not specified and not stn\n",
    "        elif affine_params is None:\n",
    "            affine_params = torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float).view(2, 3).cuda()\n",
    "            affine_params = affine_params.expand(x.size()[0], affine_params.size()[0], affine_params.size()[1]).clone()\n",
    "                    \n",
    "        x_affine = self.affine(x, affine_params)\n",
    "        mu_logvar = self.VAE.encode(x_affine)\n",
    "        z = self.VAE.reparameterize(mu_logvar, deterministic)\n",
    "        recon_x = self.VAE.decode(z)\n",
    "        recon_x = self.affine_inv(recon_x, affine_params)\n",
    "        if return_affine:\n",
    "            return recon_x, mu_logvar, affine_params, x_affine\n",
    "        else:\n",
    "            return recon_x, mu_logvar\n",
    "\n",
    "def AFFINE_MNIST_rot_perf_LATENT(model, data_loader, loss_fn, device, fixed_rotation, \n",
    "                          optimize=False, iterations=0, num_rand_restarts=200, num_imgs=1000):\n",
    "    \"\"\"Evaluate performance on MNIST Dataset using a given rotation\n",
    "    Dataloader should be MNISTCustomTRNFS with size=28x28, unnormalized, not rotated\"\"\"\n",
    "\n",
    "    with torch.cuda.device(device.index):\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (data, target) in enumerate(data_loader):\n",
    "                batch_size = data.shape[0]\n",
    "                rot_x = rotate_mnist_batch(data, return_size=40, fixed_rotation=fixed_rotation)\n",
    "                rot_x, target = rot_x.to(device), target.to(device)\n",
    "                rot_x.requires_grad = True\n",
    "                target.requires_grad = True\n",
    "                if optimize:\n",
    "                    loss = affine_model.opt_latent(rot_x, iterations=iterations, num_times=num_rand_restarts)\n",
    "                else:\n",
    "                    output = model(rot_x, deterministic=True, theta=0.0)\n",
    "                    loss = loss_fn(output, rot_x).item()\n",
    "\n",
    "                total_loss += loss * batch_size\n",
    "                if i>num_imgs:\n",
    "                    break\n",
    "\n",
    "        n_samples = len(data_loader.sampler)\n",
    "        log = {'loss': total_loss / n_samples}\n",
    "        return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_loc = '/media/rene/data/equivariance/mnist/vae_mnist_L16/0129_230250'\n",
    "VAE, data_loader, valid_data_loader, loss_fn, metric_fns, config = get_model_loaders_config(config_loc, old_gpu='cuda:1', new_gpu='cuda:0')\n",
    "VAE = VAE.to(device)\n",
    "\n",
    "AffineVAE = getattr(module_arch, 'AffineVAE')\n",
    "affine_model = TESTAffineVAE(pre_trained_VAE=VAE, img_size=28, input_dim=1, output_dim=1, latent_size=16)\n",
    "affine_model = affine_model.to(device)\n",
    "\n",
    "files_dict_loc = '/media/rene/data/MNIST/files_dict.pkl'\n",
    "data_loaders = make_generators_MNIST_CTRNFS(files_dict_loc, batch_size=1, num_workers=4, \n",
    "                                            return_size=28, rotation_range=None, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "x_affine.requires_grad True\n",
      "tensor([[[-0.1036,  0.9946,  0.0000],\n",
      "         [-0.9946, -0.1036,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "503.4684143066406\n",
      "x_affine.requires_grad True\n",
      "tensor([[[-0.1136,  0.9935,  0.0000],\n",
      "         [-0.9935, -0.1136,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "502.7657470703125\n",
      "x_affine.requires_grad True\n",
      "tensor([[[-0.1226,  0.9925,  0.0000],\n",
      "         [-0.9925, -0.1226,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "502.376953125\n",
      "x_affine.requires_grad True\n",
      "tensor([[[-0.1316,  0.9913,  0.0000],\n",
      "         [-0.9913, -0.1316,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "502.05572509765625\n",
      "x_affine.requires_grad True\n",
      "tensor([[[-0.1405,  0.9901,  0.0000],\n",
      "         [-0.9901, -0.1405,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "501.8534240722656\n",
      "0\n",
      "x_affine.requires_grad True\n",
      "tensor([[[ 0.0705, -0.9975,  0.0000],\n",
      "         [ 0.9975,  0.0705,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "681.21142578125\n",
      "x_affine.requires_grad True\n",
      "tensor([[[ 0.0606, -0.9982,  0.0000],\n",
      "         [ 0.9982,  0.0606,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "676.5647583007812\n",
      "x_affine.requires_grad True\n",
      "tensor([[[ 0.0506, -0.9987,  0.0000],\n",
      "         [ 0.9987,  0.0506,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "671.760009765625\n",
      "x_affine.requires_grad True\n",
      "tensor([[[ 0.0406, -0.9992,  0.0000],\n",
      "         [ 0.9992,  0.0406,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "667.0822143554688\n",
      "x_affine.requires_grad True\n",
      "tensor([[[ 0.0306, -0.9995,  0.0000],\n",
      "         [ 0.9995,  0.0306,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "662.5694580078125\n",
      "0\n",
      "x_affine.requires_grad True\n",
      "tensor([[[ 0.7294, -0.6841,  0.0000],\n",
      "         [ 0.6841,  0.7294,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "651.2136840820312\n",
      "x_affine.requires_grad True\n",
      "tensor([[[ 0.7362, -0.6767,  0.0000],\n",
      "         [ 0.6767,  0.7362,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "650.4682006835938\n",
      "x_affine.requires_grad True\n",
      "tensor([[[ 0.7426, -0.6697,  0.0000],\n",
      "         [ 0.6697,  0.7426,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "650.1289672851562\n",
      "x_affine.requires_grad True\n",
      "tensor([[[ 0.7488, -0.6627,  0.0000],\n",
      "         [ 0.6627,  0.7488,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "649.6043090820312\n",
      "x_affine.requires_grad True\n",
      "tensor([[[ 0.7552, -0.6555,  0.0000],\n",
      "         [ 0.6555,  0.7552,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "649.3220825195312\n",
      "0\n",
      "x_affine.requires_grad True\n",
      "tensor([[[-0.4682, -0.8836,  0.0000],\n",
      "         [ 0.8836, -0.4682,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "867.130126953125\n",
      "x_affine.requires_grad True\n",
      "tensor([[[-0.4770, -0.8789,  0.0000],\n",
      "         [ 0.8789, -0.4770,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "865.5596923828125\n",
      "x_affine.requires_grad True\n",
      "tensor([[[-0.4850, -0.8745,  0.0000],\n",
      "         [ 0.8745, -0.4850,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "863.73779296875\n",
      "x_affine.requires_grad True\n",
      "tensor([[[-0.4932, -0.8699,  0.0000],\n",
      "         [ 0.8699, -0.4932,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "862.23291015625\n",
      "x_affine.requires_grad True\n",
      "tensor([[[-0.5015, -0.8652,  0.0000],\n",
      "         [ 0.8652, -0.5015,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "860.8782958984375\n",
      "0\n",
      "x_affine.requires_grad True\n",
      "tensor([[[ 0.1205,  0.9927,  0.0000],\n",
      "         [-0.9927,  0.1205,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "466.10797119140625\n",
      "x_affine.requires_grad True\n",
      "tensor([[[ 0.1106,  0.9939,  0.0000],\n",
      "         [-0.9939,  0.1106,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "464.1249694824219\n",
      "x_affine.requires_grad True\n",
      "tensor([[[ 0.1007,  0.9949,  0.0000],\n",
      "         [-0.9949,  0.1007,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "462.5520324707031\n",
      "x_affine.requires_grad True\n",
      "tensor([[[ 0.0911,  0.9958,  0.0000],\n",
      "         [-0.9958,  0.0911,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "461.433837890625\n",
      "x_affine.requires_grad True\n",
      "tensor([[[ 0.0817,  0.9967,  0.0000],\n",
      "         [-0.9967,  0.0817,  0.0000]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "460.7001647949219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.31353234252929685}"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = AFFINE_MNIST_rot_perf_LATENT(affine_model, data_loaders['val'], loss_fn, device, fixed_rotation=45, \n",
    "                                   optimize=True, iterations=5, num_rand_restarts=1, num_imgs=3)\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000000000.0"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_AFFINE_MNIST_perf() got multiple values for argument 'fixed_rotation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-f2978c4193c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrotation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m180\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     log = get_AFFINE_MNIST_perf(affine_model, data_loaders['val'], loss_fn, metric_fns, device, fixed_rotation=rotation, \n\u001b[0;32m---> 17\u001b[0;31m                                 optimize=False, return_size=40, iterations=0, num_trials=0)\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mlog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rotation'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_AFFINE_MNIST_perf() got multiple values for argument 'fixed_rotation'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HVAE",
   "language": "python",
   "name": "hvae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
